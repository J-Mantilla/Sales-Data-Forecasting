<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8" />
        <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no" />
        <meta name="description" content="" />
        <meta name="author" content="" />
        <title>Project 4</title>
        <link rel="icon" type="image/x-icon" href="assets/favicon.ico" />
        <!-- Core theme CSS (includes Bootstrap)-->
        <link href="css/styles.css" rel="stylesheet" />
        <style>
            /* Reduce spacing between sections */
            section {
                margin-top: 20px;
                margin-bottom: 20px;
                padding-top: 20px;
                padding-bottom: 20px;
            }
            /* Center image */
            .img-center {
                display: block;
                margin-left: auto;
                margin-right: auto;
                max-width: 100%;
                height: auto;
            }
        </style>
    </head>
    <body id="page-top">
        <!-- Navigation-->
        <nav class="navbar navbar-expand-lg navbar-dark bg-dark fixed-top" id="mainNav">
            <div class="container px-4">
                <a class="navbar-brand" href="#page-top">Sales Forecasting</a>
                <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarResponsive" aria-controls="navbarResponsive" aria-expanded="false" aria-label="Toggle navigation">
                    <span class="navbar-toggler-icon"></span>
                </button>
                <div class="collapse navbar-collapse" id="navbarResponsive">
                    <ul class="navbar-nav ms-auto">
                        <li class="nav-item"><a class="nav-link" href="#introduction">Introduction</a></li>
                        <li class="nav-item"><a class="nav-link" href="#objectives">Objectives</a></li>
                        <li class="nav-item"><a class="nav-link" href="#eda">EDA</a></li>
                        <li class="nav-item"><a class="nav-link" href="#model-training">Model Training</a></li>
                        <li class="nav-item"><a class="nav-link" href="#conclusions">Conclusions</a></li>
                        <li class="nav-item"><a class="nav-link" href="#dataset">Dataset</a></li>
                        <li class="nav-item"><a class="nav-link" href="https://github.com/infinadox/Sales-Data-Forecasting.git" target="_blank">GitHub</a></li>
                    </ul>
                </div>
            </div>
        </nav>

        <!-- Header-->
        <header class="bg-primary bg-gradient text-white">
            <div class="container px-4 text-center">
                <h1 class="fw-bolder">Sales Data Forecasting for Rossmann Stores</h1>
                <p class="lead">A project by Kevin Tran, Shameer Razaak, and Juan Mantilla</p>
            </div>
        </header>

        <!-- Introduction section-->
        <section id="introduction">
            <div class="container px-4">
                <div class="row gx-4 justify-content-center">
                    <div class="col-lg-8">
                        <h2>1. Introduction</h2>
                        <p>The objective of this project is to develop a time series forecasting model to predict daily sales for Rossmann stores. By leveraging historical sales data and various store attributes, we aim to create an accurate predictive model that can assist in business planning and inventory management.</p>
                        <!-- Logo Image -->
                        <img src="images/sc00.jpg" alt="Project Logo" class="img-center">
                    </div>
                </div>
            </div>
        </section>

        <!-- Objectives section-->
        <section id="objectives">
            <div class="container px-4">
                <div class="row gx-4 justify-content-center">
                    <div class="col-lg-8">
                        <h2>2. Project Objectives</h2>
                        <ul>
                            <li>To retrieve and process sales data from the Rossmann Stores dataset.</li>
                            <li>To perform exploratory data analysis (EDA) to understand sales trends and patterns.</li>
                            <li>To engineer relevant features that improve the model's predictive power.</li>
                            <li>With advancements of Deep Learning, to further improve performance, LSTM might be a good point to start.</li>
                            <li>To develop and optimize a time series forecasting model that achieves at least 0.80 R-squared.</li>
                            <li>To document the entire process, including data preprocessing, model development, and evaluation.</li>
                            <li>To present the findings clearly and engagingly.</li>
                        </ul>
                    </div>
                </div>
            </div>
        </section>

        <!-- EDA section-->
        <section class="bg-light" id="eda">
            <div class="container px-4">
                <div class="row gx-4 justify-content-center">
                    <div class="col-lg-8">
                        <h2>3. EDA</h2>
                        <h3>Store sales are influenced by many factors including:</h3>
                        <ul>
                            <li>Promotions</li>
                            <li>Holidays</li>
                            <li>Competition</li>
                            <li>Seasonality</li>
                            <li>Locality</li>
                        </ul>
                        
                        <!-- Sales vs Customers Graph -->
                        <h3>Sales vs Customers Comparison:</h3>
                        <img src="images/sc1.png" alt="Sales vs Customers Graph" class="img-center">
                        <!-- Sales per Day Graph -->
                        <h3>Sales per Day:</h3>
                        <img src="images/sc2.png" alt="Sales per Day Graph" class="img-center">
                        <!-- Customers per Day Graph -->
                        <h3>Customers per Day:</h3>
                        <img src="images/sc3.png" alt="Customers per Day Graph" class="img-center">
                        <h3>Sales per Customers per Day:</h3>
                        <img src="images/sc4.png" alt="Sales per Customers Graph" class="img-center">
                        <h3>Sales per Week - Average Sales per Week:</h3>
                        <img src="images/sc5.png" alt="Average Sales per Week Graph" class="img-center">
                        <h3>Weekday Sales Monday - Sunday:</h3>
                        <img src="images/sc6.png" alt="Weekday Sales Monday - Sunday Graph" class="img-center">
                        <h3>Sales Overtime - 6 Weeks:</h3>
                        <img src="images/sc9.png" alt="Sales Overtime Graph" class="img-center">
                        <h3>Locality:</h3>
                        <img src="images/sc7.png" alt="Locality Graph" class="img-center">
                        <h3>Seasonality:</h3>
                        <img src="images/sc12.png" alt="Seasonality Graph" class="img-center">
                        <h3>Promotions:</h3>
                        <img src="images/sc10.png" alt="Promotions Graph" class="img-center">
                    </div>
                </div>
            </div>
        </section>

<!-- Model Training section-->
<section id="model-training">
    <div class="container px-4">
        <div class="row gx-4 justify-content-center">
            <div class="col-lg-8">
                <h2>4. Model Training</h2>
                <ul>
                    <li><strong>Ensure Dependencies are Installed</strong><br>
                    Make sure you have all the required libraries installed. You can install them using pip if needed:
                    <pre><code>pip install numpy pandas matplotlib scikit-learn</code></pre>
                    </li>
                    <li><strong>Save the Code to a Python Script</strong><br>
                    Save the provided code in a Python script file, for example, <code>Random_forest.py</code>.
                    </li>
                    <li><strong>Run the Script</strong><br>
                    Run the script from the command line or an IDE that supports Python. If you're using the command line, navigate to the directory containing your script and execute:
                    <pre><code>python Random_forest.py</code></pre>
                    </li>
                    <li><strong>Understanding the Code</strong><br>
                    Hereâ€™s a quick overview of what each part of the script does:
                    <ul>
                        <li><strong>Data Loading and Preprocessing:</strong> Loads and normalizes the data.</li>
                        <li><strong>Feature Creation:</strong> Creates lag features for the Random Forest model.</li>
                        <li><strong>Training and Evaluation:</strong> Trains the Random Forest model and evaluates its performance.</li>
                        <li><strong>Plotting Results:</strong> Plots the results of predictions and saves them.</li>
                        <li><strong>Forecasting:</strong> Forecasts future sales and saves the results.</li>
                    </ul>
                    </li>
                    
                </ul>
                
    
    <h2>What is Random Forest?</h2>
    <p>Random Forest is a popular machine learning algorithm that combines multiple decision trees to improve accuracy. It can handle both classification (e.g., spam vs. not spam) and regression (e.g., predicting house prices) tasks well.</p>
    
    <h3>Decision Trees</h3>
    <p>Decision trees make decisions by asking a series of questions based on features of the data. Each tree can have issues like bias or overfitting, but Random Forest reduces these issues by combining many trees.</p>
    
    <h3>Ensemble Methods</h3>
    <p>Random Forest is an ensemble method that uses:</p>
    <ul>
        <li><strong>Bagging</strong>: Training multiple models on different samples of data and averaging their results to reduce variance.</li>
        <li><strong>Feature Randomness</strong>: Training each tree on different subsets of features to improve accuracy and reduce correlation among trees.</li>
    </ul>
    
    <h3>How It Works</h3>
    <p><strong>Node Size, Number of Trees, Number of Features</strong>: Key settings for the model.</p>
    <p><strong>Training</strong>: Each tree is trained on a random sample of the data, and predictions are made by averaging (for regression) or voting (for classification).</p>
    <p><strong>Out-of-Bag Samples</strong>: Used for cross-validation to assess model performance.</p>
    
    <h3>Benefits</h3>
    <ul>
        <li>Reduces risk of overfitting.</li>
        <li>Flexible for various tasks.</li>
        <li>Helps identify important features.</li>
    </ul>
    
    <h3>Challenges</h3>
    <ul>
        <li>Can be time-consuming and resource-intensive.</li>
        <li>More complex to interpret than a single decision tree.</li>
    </ul>
    
    <h3>Applications</h3>
    <ul>
        <li><strong>Finance</strong>: Credit risk evaluation, fraud detection, option pricing.</li>
        <li><strong>Healthcare</strong>: Gene classification, biomarker discovery, drug response prediction.</li>
        <li><strong>E-commerce</strong>: Recommendations, cross-selling.</li>
    </ul>

                <!-- Model Performance Interpretation -->
                <h2>Early Iteration</h2>
                <p><strong>Training Loss (MSE):</strong> 0.0004147702751754034</p>
                <p><strong>Validation Loss (MSE):</strong> 0.0028658269385234197</p>
                
                <h3>Performance Interpretation: </h3>
                <p>
                    The model's performance is evaluated using two key metrics: Training Loss and Validation Loss. These metrics will determine if there is a case of overfitting or underfitting.
                </p>
                <p>
                    The <strong>Training Loss (MSE) 0.0004147702751754034:</strong> This value is very low, suggesting that the model fits the training data well and has learned the underlying patterns from it effectively.
                </p>
                <p>
                    The <strong>
                        Validation Loss (MSE) 0.0028658269385234197: </strong> This value is significantly higher than the Training Loss, indicating that the model's performance on new, unseen data is not as strong as it is on the training data.
                </p>
                <h3>Interpretations </h3>
                <p>
                    The discrepancy between the low Training Loss and higher Validation Loss suggests that the model might be overfitting. While it performs excellently on the training data, it struggles to generalize to new data. Overfitting occurs when a model learns the training data too well, including its noise and outliers, which negatively impacts its performance on validation data. This suggests the need for strategies to improve generalization, such as regularization or model simplification
                </p>
                <h3>Recommendations:</h3>
                <p>
                    To address this, you might consider:
                </p>
                <ul>
                    <li>Applying regularization techniques (e.g., L1/L2 regularization) to reduce overfitting.</li>
                </ul>
                <h2>Final Performance Results</h2>
                <p><strong>Training Loss (MSE):</strong> 0.0033199530559485</p>
                <p><strong>Validation Loss (MSE):</strong> 0.006474465520687854</p>
                <p><strong>Cross-validated MSE:</strong>  0.006220120581014061</p>    
                <!-- Summary of Updates -->
                <h2>Summary of Updates</h2>
                <p><strong>Model Regularization:</strong><br>
                Improved model generalization by adding constraints to prevent overfitting:
                <ul>
                    <li><strong>max_depth=10:</strong> Limits the maximum depth of the trees to prevent overfitting.</li>
                    <li><strong>min_samples_split=10:</strong> Increases the minimum number of samples required to split an internal node.</li>
                    <li><strong>min_samples_leaf=5:</strong> Increases the minimum number of samples required to be at a leaf node.</li>
                    <li><strong>max_features='sqrt':</strong> Limits the number of features considered for the best split to the square root of the total number of features.</li>
                </ul>
                </p>
                <p><strong>Cross-Validation:</strong><br>
                Enhanced model evaluation with cross-validation:
                <ul>
                    <li>Added cross-validation using <code>cross_val_score</code> to assess model performance more robustly.</li>
                    <li>Calculated cross-validated MSE and saved it to performance metrics.</li>
                </ul>
                </p>
                <p><strong>Forecasting:</strong><br>
                Added functionality to forecast future sales for the next 42 days:
                <ul>
                    <li><strong>forecast_sales function:</strong> Predicts future values and returns the forecasted values and corresponding dates.</li>
                    <li>Included forecasts for future sales starting from the last date in the dataset.</li>
                    <li>Added functionality to forecast sales for 42 days after a specific date (2015-07-31).</li>
                </ul>
                </p>
                <p><strong>Plotting:</strong><br>
                Added plotting of the forecast results:
                <ul>
                    <li>Plotted historical sales and forecasted sales for the next 42 days.</li>
                    <li>Plotted historical sales and forecasted sales for the 42 days after 2015-07-31.</li>
                </ul>
                </p>
                <p><strong>Saving Results:</strong><br>
                Saved forecast results to CSV files and plots to PNG files:
                <ul>
                    <li><strong>sales_forecast.csv:</strong> For general forecast results.</li>
                    <li><strong>sales_forecast_after_2015-07-31.csv:</strong> For forecast results starting from 2015-07-31.</li>
                    <li>Added PNG plots for visualizing the forecasts.</li>
                </ul>
                </p>

                <!-- Add graphs below the Post-Modeling Analysis section -->
                <h3>EDA performed on CSV files generated by the machine learning model</h3>
                <div class="graph-container">
                    <img src="images/sc14.png" alt="Total Forecast Sales by Day Graph" class="img-center">
                    <p><strong>Graph 1:</strong> Total Forecast Sales by Day</p>
                </div>
                <div class="graph-container">
                    <img src="images/sc13.png" alt="Average Forecast Sales by Week Graph" class="img-center">
                    <p><strong>Graph 2:</strong> Average Forecast Sales per Week</p>
                </div>
                <div class="graph-container">
                    <img src="images/sc15.png" alt="42 Day Sales Forecast" class="img-center">
                    <p><strong>Graph 3:</strong> 42 Day Sales Forecast</p>
                </div>
            </div>
        </div>
    </div>
</section>




    
        <!-- Conclusions section-->
        <section id="conclusions">
            <div class="container px-4">
                <div class="row gx-4 justify-content-center">
                    <div class="col-lg-8">
                        <h2>5. Conclusions of EDA:</h2>
                        <ul>
                            <li>The most selling and crowded store type is B.</li>
                            <li>Sales are highly correlated with the number of Customers.</li>
                            <li>For all stores, promotions lead to an increase in both Sales and Customers.</li>
                            <li>Stores open during School Holidays have more sales than on normal days.</li>
                            <li>More stores are open during School holidays than State holidays.</li>
                            <li>Sales increase during Christmas week, likely because people buy more beauty products for Christmas celebrations.</li>
                            <li>The absence of values in features like CompetitionOpenSinceYear/Month doesnâ€™t indicate a lack of competition, as CompetitionDistance values are not null where the other two values are null.</li>
                            <li>After analyzing sales using Fourier decomposition, there appears to be a slight seasonality component in the Sales data.</li>
                            <li>Saturdays are a popular day for shoppers in terms of days of the week, potentially because Rossman stores are closed on Sundays </li>
                        </ul>
                    </div>
                </div>
            </div>
        </section>

        <!-- Dataset section-->
        <section id="dataset">
            <div class="container px-4">
                <div class="row gx-4 justify-content-center">
                    <div class="col-lg-8">
                        <h2>6. Dataset Description</h2>
                        <p>Dataset Source: Kaggle Rossmann Store Sales Dataset</p>
                        <p>Link: <a href="https://www.kaggle.com/c/rossmann-store-sales/data">https://www.kaggle.com/c/rossmann-store-sales/data</a></p>
                    </div>
                </div>
            </div>
        </section>

        <!-- Footer-->
        <footer class="py-5 bg-dark">
            <div class="container px-4">
                <p class="m-0 text-center text-white">Copyright &copy; project 4 2024</p>
            </div>
        </footer>

        <!-- Bootstrap core JS-->
        <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.2.3/dist/js/bootstrap.bundle.min.js"></script>
        <!-- Core theme JS-->
        <script src="js/scripts.js"></script>
    </body>
</html>
